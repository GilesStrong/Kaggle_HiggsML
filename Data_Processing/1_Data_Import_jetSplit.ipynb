{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data, compute features, train-val split, feature selection, pre-process, & save\n",
    "## Import\n",
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/giles/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "os.environ['MKL_THREADING_LAYER']='GNU'\n",
    "sys.path.append('../')\n",
    "from Modules.Basics import *\n",
    "from ML_Tools.General.Feature_Selection import *\n",
    "from ML_Tools.Transformations.HEP_Proc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(name):\n",
    "    data = pandas.read_csv(dirLoc + name + '.csv')\n",
    "    data.rename(index=str, columns={\"Weight\": \"gen_weight\", 'PRI_met':'PRI_met_pt'}, inplace=True)\n",
    "    data['gen_target'] = 0\n",
    "    if name == 'training':\n",
    "        data.loc[data.Label == 's', 'gen_target'] = 1\n",
    "        data.drop(columns=['Label'], inplace=True)        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = importData('training')\n",
    "testingData = importData('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print [x for x in trainingData.columns], len(trainingData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate = True\n",
    "cartesian = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateEvent(inData):\n",
    "    '''Rotate event in phi such that lepton is at phi == 0'''\n",
    "    inData['PRI_tau_phi'] = deltaphi(inData['PRI_lep_phi'], inData['PRI_tau_phi'])\n",
    "    inData['PRI_jet_leading_phi'] = deltaphi(inData['PRI_lep_phi'], inData['PRI_jet_leading_phi'])\n",
    "    inData['PRI_jet_subleading_phi'] = deltaphi(inData['PRI_lep_phi'], inData['PRI_jet_subleading_phi'])\n",
    "    inData['PRI_met_phi'] = deltaphi(inData['PRI_lep_phi'], inData['PRI_met_phi'])\n",
    "    \n",
    "def convertData(inData):\n",
    "    '''Pass data through conversions and drop uneeded columns'''\n",
    "    \n",
    "    inData.loc[inData['DER_mass_MMC'] == -999.0, 'DER_mass_MMC'] = -1\n",
    "    \n",
    "    if rotate:\n",
    "        rotateEvent(inData)\n",
    "    \n",
    "    if cartesian:\n",
    "        moveToCartesian(inData, 'PRI_tau', drop=True)\n",
    "        moveToCartesian(inData, 'PRI_lep', drop=True)\n",
    "        moveToCartesian(inData, 'PRI_jet_leading', drop=True)\n",
    "        moveToCartesian(inData, 'PRI_jet_subleading', drop=True)\n",
    "        moveToCartesian(inData, 'PRI_met', z=False)\n",
    "        \n",
    "        inData.drop(columns=[\"PRI_met_phi\"], inplace=True)\n",
    "        \n",
    "    if rotate and not cartesian:\n",
    "        inData.drop(columns=[\"PRI_lep_phi\"], inplace=True)\n",
    "    elif rotate and cartesian:\n",
    "        inData.drop(columns=[\"PRI_lep_py\"], inplace=True)\n",
    "        \n",
    "    inData.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    inData.fillna(-999.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertData(trainingData)\n",
    "convertData(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split by jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitByJet(inData):\n",
    "    outData = {}\n",
    "    \n",
    "    outData[0] = inData[inData['PRI_jet_num'] == 0]\n",
    "    outData[1] = inData[inData['PRI_jet_num'] == 1]    \n",
    "    outData[2] = inData[inData['PRI_jet_num'] >= 2] \n",
    "    \n",
    "    if not cartesian:\n",
    "    \n",
    "        outData[0].drop(columns={'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality',\n",
    "                                 'PRI_jet_num', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n",
    "                                 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', \n",
    "                                 'PRI_jet_all_pt'}, inplace=True)\n",
    "\n",
    "        outData[1].drop(columns={'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality',\n",
    "                                 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi',\n",
    "                                 'PRI_jet_all_pt'}, inplace=True)\n",
    "\n",
    "    elif cartesian:\n",
    "        outData[0].drop(columns={'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality',\n",
    "                                 'PRI_jet_num', 'PRI_jet_leading_px', 'PRI_jet_leading_py', 'PRI_jet_leading_pz',\n",
    "                                 'PRI_jet_subleading_px', 'PRI_jet_subleading_py', 'PRI_jet_subleading_pz', \n",
    "                                 'PRI_jet_all_pt'}, inplace=True)\n",
    "\n",
    "        outData[1].drop(columns={'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality',\n",
    "                                 'PRI_jet_subleading_px', 'PRI_jet_subleading_py', 'PRI_jet_subleading_pz',\n",
    "                                 'PRI_jet_all_pt'}, inplace=True)\n",
    "    \n",
    "    return outData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitJetTraining = splitByJet(trainingData)\n",
    "splitJetTesting = splitByJet(testingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in splitJetTraining:\n",
    "    print i, len([x for x in splitJetTraining[i].columns if 'gen' not in x and 'EventId' not in x]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPipe(inData, features):\n",
    "    inputPipe, outputPipe = getPreProcPipes(normIn=True)\n",
    "    inputPipe.fit(inData[features].values.astype('float32'))\n",
    "    return inputPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveBatch(inData, n, inputPipe, outFile, normWeights, mode, features):\n",
    "    grp = outFile.create_group('fold_' + str(n))\n",
    "    \n",
    "    X = inputPipe.transform(inData[features].values.astype('float32'))\n",
    "    \n",
    "    inputs = grp.create_dataset(\"inputs\", shape=X.shape, dtype='float32')\n",
    "    inputs[...] = X\n",
    "    \n",
    "    if 'testing' not in mode:\n",
    "        if normWeights:\n",
    "            inData.loc[inData.gen_target == 0, 'gen_weight'] = inData.loc[inData.gen_target == 0, 'gen_weight']/np.sum(inData.loc[inData.gen_target == 0, 'gen_weight'])\n",
    "            inData.loc[inData.gen_target == 1, 'gen_weight'] = inData.loc[inData.gen_target == 1, 'gen_weight']/np.sum(inData.loc[inData.gen_target == 1, 'gen_weight'])\n",
    "\n",
    "        X_weights = inData['gen_weight'].values.astype('float32')\n",
    "        y = inData['gen_target'].values.astype('int')\n",
    "\n",
    "        targets = grp.create_dataset(\"targets\", shape=y.shape, dtype='int')\n",
    "        targets[...] = y\n",
    "\n",
    "        weights = grp.create_dataset(\"weights\", shape=X_weights.shape, dtype='float32')\n",
    "        weights[...] = X_weights\n",
    "    \n",
    "    else:\n",
    "        X_EventId = inData['EventId'].values.astype('int')\n",
    "        \n",
    "        EventId = grp.create_dataset(\"EventId\", shape=X_EventId.shape, dtype='int')\n",
    "        EventId[...] = X_EventId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareSample(inData, mode, inputPipe, normWeights, N=10):\n",
    "    print \"Running\", mode\n",
    "    os.system('rm ' + dirLoc + mode + '.hdf5')\n",
    "    outFile = h5py.File(dirLoc + mode + '.hdf5', \"w\")\n",
    "    \n",
    "    features = [x for x in inData.columns if 'gen' not in x and 'EventId' not in x]\n",
    "    \n",
    "    if isinstance(inputPipe, types.NoneType):\n",
    "        inputPipe = getPipe(inData, features)\n",
    "            \n",
    "    kf = StratifiedKFold(n_splits=N, shuffle=True)\n",
    "    folds = kf.split(inData, inData['gen_target'])\n",
    "    \n",
    "    for i, (train, test) in enumerate(folds):\n",
    "        print \"Saving fold:\", i, \"of\", len(test), \"events\"\n",
    "        saveBatch(inData.iloc[test], i, inputPipe, outFile, normWeights, mode, features)\n",
    "        \n",
    "    return inputPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in splitJetTraining:\n",
    "    print \"Splitting to validation\"\n",
    "    trainIndeces, valIndeces = splitDevVal(splitJetTraining[i])\n",
    "    train = splitJetTraining[i].loc[trainIndeces]\n",
    "    val = splitJetTraining[i].loc[valIndeces]\n",
    "    print len(train), \"training\", len(val), \"validation\"\n",
    "        \n",
    "    inputPipe = prepareSample(train, 'train_' + str(i), None, True)\n",
    "    prepareSample(val, 'val_' + str(i), inputPipe, False)\n",
    "    \n",
    "    prepareSample(splitJetTesting[i], 'testing_'+ str(i), inputPipe, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
