{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day x\n",
    "batch size 256 lr 1e-3, normed weighted, non-rotated, cartesian, SWA renwal test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "#os.environ['MKL_THREADING_LAYER']='GNU'\n",
    "sys.path.append('../')\n",
    "from Modules.Basics import *\n",
    "from Modules.Class_Basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classTrainFeatures = ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_met_pt', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_all_pt', 'PRI_tau_px', 'PRI_tau_py', 'PRI_tau_pz', 'PRI_lep_px', 'PRI_lep_py', 'PRI_lep_pz', 'PRI_jet_leading_px', 'PRI_jet_leading_py', 'PRI_jet_leading_pz', 'PRI_jet_subleading_px', 'PRI_jet_subleading_py', 'PRI_jet_subleading_pz', 'PRI_met_px', 'PRI_met_py']\n",
    "classModel = 'modelSwish'\n",
    "varSet = \"basic_features\"\n",
    "\n",
    "nSplits = 10\n",
    "ensembleSize = 10\n",
    "ensembleMode = 'loss'\n",
    "\n",
    "maxEpochs = 200\n",
    "compileArgs = {'loss':'binary_crossentropy', 'optimizer':'adam'}\n",
    "trainParams = {'epochs' : 1, 'batch_size' : 256, 'verbose' : 0}\n",
    "modelParams = {'version':classModel, 'nIn':len(classTrainFeatures), 'compileArgs':compileArgs, 'mode':'classifier'}\n",
    "\n",
    "print(\"\\nTraining on\", len(classTrainFeatures), \"features:\", [var for var in classTrainFeatures])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'rb') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'train.hdf5', \"r+\"),\n",
    "                                    inputPipe=inputPipe, augRotMult=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(getFeature('weights', h5py.File(dirLoc + 'val.hdf5', \"r+\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lrFinder = batchLRFind(trainData, getModel, modelParams, trainParams,\n",
    "                       lrBounds=[1e-5,2e-1], trainOnWeights=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compileArgs['lr'] = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batchTrainClassifier(batchYielder, nSplits, modelGen, modelGenParams, trainParams,\n",
    "                         cosAnnealMult=0, reverseAnneal=False, plotLR=False, reduxDecay=False,\n",
    "                         annealMomentum=False, reverseAnnealMomentum=False, plotMomentum=False,\n",
    "                         oneCycle=False, ratio=0.25, reverse=False, lrScale=10, momScale=10, plotOneCycle=False, scale=30, mode='sgd',\n",
    "                         swaStart=-1, swaRenewal=-1,\n",
    "                         trainOnWeights=True,\n",
    "                         saveLoc='train_weights/', patience=10, maxEpochs=10000,\n",
    "                         verbose=False, logoutput=False):\n",
    "    \n",
    "    os.system(\"mkdir \" + saveLoc)\n",
    "    os.system(\"rm \" + saveLoc + \"*.h5\")\n",
    "    os.system(\"rm \" + saveLoc + \"*.json\")\n",
    "    os.system(\"rm \" + saveLoc + \"*.pkl\")\n",
    "    os.system(\"rm \" + saveLoc + \"*.png\")\n",
    "    os.system(\"rm \" + saveLoc + \"*.log\")\n",
    "    \n",
    "    if logoutput:\n",
    "        old_stdout = sys.stdout\n",
    "        log_file = open(saveLoc + 'training_log.log', 'w')\n",
    "        sys.stdout = log_file\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    results = []\n",
    "    histories = []\n",
    "    binary = None\n",
    "\n",
    "    if not isinstance(batchYielder, BatchYielder):\n",
    "        print (\"HDF5 as input is depreciated, converting to BatchYielder\")\n",
    "        batchYielder = BatchYielder(batchYielder)\n",
    "\n",
    "    if cosAnnealMult: print (\"Using cosine annealing\")\n",
    "    if trainOnWeights: print (\"Training using weights\")\n",
    "\n",
    "    for fold in range(nSplits):\n",
    "        foldStart = timeit.default_timer()\n",
    "        print (\"Running fold\", fold+1, \"/\", nSplits)\n",
    "        os.system(\"rm \" + saveLoc + \"best.h5\")\n",
    "        best = -1\n",
    "        bestLR = -1\n",
    "        reduxDecayActive = False\n",
    "        tmpPatience = patience\n",
    "        epochCounter = 0\n",
    "        subEpoch = 0\n",
    "        stop = False\n",
    "        lossHistory = {'val_loss':[], 'swa_val_loss':[]}\n",
    "        trainID, testID = getFolds(fold, nSplits) #Get fold indeces for training and testing for current fold\n",
    "\n",
    "        model = None\n",
    "        model = modelGen(**modelGenParams)\n",
    "        model.reset_states #Just checking\n",
    "        \n",
    "        testbatch = batchYielder.getBatch(testID) #Load testing fold\n",
    "\n",
    "        callbacks = []\n",
    "        if cosAnnealMult:\n",
    "            cosAnneal = CosAnneal(math.ceil(len(batchYielder.source['fold_0/targets'])/trainParams['batch_size']), cosAnnealMult, reverseAnneal)\n",
    "            callbacks.append(cosAnneal)\n",
    "        \n",
    "        if annealMomentum:\n",
    "            cosAnnealMomentum = CosAnnealMomentum(math.ceil(len(batchYielder.source['fold_0/targets'])/trainParams['batch_size']), cosAnnealMult, reverseAnnealMomentum)\n",
    "            callbacks.append(cosAnnealMomentum)    \n",
    "\n",
    "        if oneCycle:\n",
    "            oneCycle = OneCycle(math.ceil(len(batchYielder.source['fold_0/targets'])/trainParams['batch_size']), ratio=ratio, reverse=reverse, lrScale=lrScale, momScale=momScale, scale=scale, mode=mode)\n",
    "            callbacks.append(oneCycle)  \n",
    "        \n",
    "        if swaStart >= 0:\n",
    "            if cosAnnealMult:\n",
    "                swa = _SWA(swaStart, testbatch, modelGen(**modelGenParams), verbose, swaRenewal, cosAnneal, trainOnWeights=trainOnWeights)\n",
    "            else:\n",
    "                swa = _SWA(swaStart, testbatch, modelGen(**modelGenParams), verbose, swaRenewal, trainOnWeights=trainOnWeights)\n",
    "            callbacks.append(swa)\n",
    "        useSWA = False\n",
    "\n",
    "        for epoch in range(maxEpochs):\n",
    "            for n in trainID: #Loop through training folds\n",
    "                trainbatch = batchYielder.getBatch(n) #Load fold data\n",
    "                subEpoch += 1\n",
    "                \n",
    "                if binary == None: #First run, check classification mode\n",
    "                    binary = True\n",
    "                    nClasses = len(np.unique(trainbatch['targets']))\n",
    "                    if nClasses > 2:\n",
    "                        print (nClasses, \"classes found, running in multiclass mode\\n\")\n",
    "                        trainbatch['targets'] = utils.to_categorical(trainbatch['targets'], num_classes=nClasses)\n",
    "                        binary = False\n",
    "                    else:\n",
    "                        print (nClasses, \"classes found, running in binary mode\\n\")\n",
    "\n",
    "                if trainOnWeights:\n",
    "                    model.fit(trainbatch['inputs'], trainbatch['targets'],\n",
    "                              class_weight = 'auto', sample_weight=trainbatch['weights'],\n",
    "                              callbacks = callbacks, **trainParams) #Train for one epoch\n",
    "\n",
    "                    if swaStart >= 0 and swa.active:\n",
    "                        losses = swa.get_losses()\n",
    "                        print('{} swa loss {}, default loss {}'.format(subEpoch, losses['swa'], losses['base']))\n",
    "                        if losses['swa'] < losses['base']:\n",
    "                            loss = losses['swa']\n",
    "                            useSWA = True\n",
    "                        else:\n",
    "                            loss = losses['base']\n",
    "                            useSWA = False\n",
    "                        \n",
    "                    else:\n",
    "                        loss = model.evaluate(testbatch['inputs'], testbatch['targets'], sample_weight=testbatch['weights'], verbose=0)\n",
    "                    \n",
    "                else:\n",
    "                    model.fit(trainbatch['inputs'], trainbatch['targets'],\n",
    "                              class_weight = 'auto',\n",
    "                              callbacks = callbacks, **trainParams) #Train for one epoch\n",
    "                    \n",
    "                    if swaStart >= 0 and swa.active:\n",
    "                        losses = swa.get_losses()\n",
    "                        print('{} swa loss {}, default loss {}'.format(subEpoch, losses['swa'], losses['base']))\n",
    "                        if losses['swa'] < losses['base']:\n",
    "                            loss = losses['swa']\n",
    "                            useSWA = True\n",
    "                        else:\n",
    "                            loss = losses['base']\n",
    "                            useSWA = False\n",
    "                    else:\n",
    "                        loss = model.evaluate(testbatch['inputs'], testbatch['targets'], verbose=0)\n",
    "                \n",
    "                if swaStart >= 0 and swa.active and cosAnnealMult > 1:\n",
    "                    print (\"{} SWA loss:\", subEpoch, loss)\n",
    "                \n",
    "                if swaStart >= 0:\n",
    "                    if swa.active:\n",
    "                        lossHistory['swa_val_loss'].append(losses['swa'])\n",
    "                        lossHistory['val_loss'].append(losses['base'])\n",
    "                    else:\n",
    "                        lossHistory['swa_val_loss'].append(loss)\n",
    "                        lossHistory['val_loss'].append(loss)\n",
    "                        \n",
    "\n",
    "                if loss <= best or best < 0: #Save best\n",
    "                    best = loss\n",
    "                    if cosAnnealMult:\n",
    "                        if cosAnneal.lrs[-1] > 0:\n",
    "                            bestLR = cosAnneal.lrs[-1]\n",
    "                        else:\n",
    "                            bestLR = cosAnneal.lrs[-2]\n",
    "                    epochCounter = 0\n",
    "                    if swaStart >= 0 and swa.active and useSWA:\n",
    "                        swa.test_model.save_weights(saveLoc + \"best.h5\")\n",
    "                    else:\n",
    "                        model.save_weights(saveLoc + \"best.h5\")\n",
    "                    if reduxDecayActive:\n",
    "                        cosAnneal.lrs.append(float(K.get_value(model.optimizer.lr)))\n",
    "                    if verbose:\n",
    "                        print ('{} New best found: {}'.format(subEpoch, best))\n",
    "                elif cosAnnealMult and not reduxDecayActive:\n",
    "                    if cosAnneal.cycle_end:\n",
    "                        epochCounter += 1\n",
    "                else:\n",
    "                    epochCounter += 1\n",
    "                    if reduxDecayActive:\n",
    "                        lr = 0.8*float(K.get_value(model.optimizer.lr))\n",
    "                        cosAnneal.lrs.append(lr)\n",
    "                        K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "                if epochCounter >= tmpPatience: #Early stopping\n",
    "                    if cosAnnealMult and reduxDecay and not reduxDecayActive:\n",
    "                        print ('CosineAnneal stalling after {} epochs, entering redux decay at LR={}'.format(subEpoch, bestLR))\n",
    "                        model.load_weights(saveLoc +  \"best.h5\")\n",
    "                        cosAnneal.lrs.append(bestLR)\n",
    "                        K.set_value(model.optimizer.lr, bestLR)\n",
    "                        tmpPatience = 10\n",
    "                        epochCounter = 0\n",
    "                        callbacks = []\n",
    "                        reduxDecayActive = True\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print ('Early stopping after {} epochs'.format(subEpoch))\n",
    "                        stop = True\n",
    "                        break\n",
    "            \n",
    "            if stop:\n",
    "                break\n",
    "\n",
    "        model.load_weights(saveLoc +  \"best.h5\")\n",
    "\n",
    "        histories.append({})\n",
    "        histories[-1]['val_loss'] = lossHistory['val_loss']\n",
    "        if swaStart >= 0:\n",
    "            histories[-1]['swa_val_loss'] = lossHistory['swa_val_loss']\n",
    "        \n",
    "        results.append({})\n",
    "        results[-1]['loss'] = best\n",
    "        if binary:\n",
    "            testbatch = batchYielder.getBatch(testID) #Load testing fold\n",
    "            if not isinstance(testbatch['weights'], type(None)):\n",
    "                results[-1]['wAUC'] = 1-roc_auc_score(testbatch['targets'],\n",
    "                                                     model.predict(testbatch['inputs'], verbose=0),\n",
    "                                                     sample_weight=testbatch['weights'])\n",
    "            results[-1]['AUC'] = 1-roc_auc_score(testbatch['targets'],\n",
    "                                                 model.predict(testbatch['inputs'], verbose=0))\n",
    "        print (\"Score is:\", results[-1])\n",
    "\n",
    "        if plotLR: cosAnneal.plot_lr()\n",
    "        if plotMomentum: cosAnnealMomentum.plot_momentum()\n",
    "        if plotOneCycle: oneCycle.plot()\n",
    "\n",
    "        print(\"Fold took {:.3f}s\\n\".format(timeit.default_timer() - foldStart))\n",
    "\n",
    "        model.save(saveLoc +  'train_' + str(fold) + '.h5')\n",
    "        with open(saveLoc +  'resultsFile.pkl', 'wb') as fout: #Save results\n",
    "            pickle.dump(results, fout)\n",
    "\n",
    "    print(\"\\n______________________________________\")\n",
    "    print(\"Training finished\")\n",
    "    print(\"Cross-validation took {:.3f}s \".format(timeit.default_timer() - start))\n",
    "    plotTrainingHistory(histories, save=saveLoc + 'loss_history.png')\n",
    "    for score in results[0]:\n",
    "        mean = uncertRound(np.mean([x[score] for x in results]), np.std([x[score] for x in results])/np.sqrt(len(results)))\n",
    "        print (\"Mean\", score, \"= {} +- {}\".format(mean[0], mean[1]))\n",
    "    print(\"______________________________________\\n\")\n",
    "                      \n",
    "    if logoutput:\n",
    "        sys.stdout = old_stdout\n",
    "        log_file.close()\n",
    "    return results, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SWA(Callback):\n",
    "    '''Based on fastai version'''\n",
    "    def __init__(self, swa_start, testBatch, testModel, verbose=False, swaRenewal=-1,\n",
    "                 clrCallback=None, trainOnWeights=False, sgdReplacement=False):\n",
    "        super(_SWA, self).__init__()\n",
    "        self.swa_model = None\n",
    "        self.swa_model_new = None\n",
    "        self.swa_start = swa_start\n",
    "        self.epoch = -1\n",
    "        self.swa_n = -1\n",
    "        self.swaRenewal = swaRenewal\n",
    "        self.n_since_renewal = -1\n",
    "        self.losses = {'swa':None, 'base':None}\n",
    "        self.active = False\n",
    "        self.testBatch = testBatch\n",
    "        self.weighted = trainOnWeights\n",
    "        self.clrCallback = clrCallback\n",
    "        self.test_model = testModel\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        if isinstance(self.swa_model, type(None)):\n",
    "            self.swa_model = self.model.get_weights()\n",
    "            self.swa_model_new = self.model.get_weights()\n",
    "            self.epoch = 0\n",
    "            self.swa_n = 0\n",
    "            self.n_since_renewal = 0\n",
    "            self.first_completed= False\n",
    "            self.cylcle_since_replacement = 1\n",
    "            \n",
    "    def on_epoch_begin(self, metrics, logs={}):\n",
    "        self.losses = {'swa':None, 'base':None}\n",
    "\n",
    "    def on_epoch_end(self, metrics, logs={}):\n",
    "        if (self.epoch + 1) >= self.swa_start and (isinstance(self.clrCallback, type(None)) or self.clrCallback.cycle_end):\n",
    "            if self.swa_n == 0:\n",
    "                print (\"SWA beginning\")\n",
    "                self.active = True\n",
    "            elif not isinstance(self.clrCallback, type(None)) and self.clrCallback.cycle_mult > 1:\n",
    "                print (\"Updating average\")\n",
    "                self.active = True\n",
    "            self.update_average_model()\n",
    "            self.swa_n += 1\n",
    "            \n",
    "            if self.swa_n > self.swaRenewal:\n",
    "                self.first_completed = True\n",
    "                self.n_since_renewal += 1\n",
    "                if self.n_since_renewal > self.cylcle_since_replacement*self.swaRenewal and self.swaRenewal > 0:\n",
    "                    self.compareAverages()\n",
    "            \n",
    "        if isinstance(self.clrCallback, type(None)) or self.clrCallback.cycle_end:\n",
    "            self.epoch += 1\n",
    "\n",
    "        if self.active and not (isinstance(self.clrCallback, type(None)) or self.clrCallback.cycle_end or self.clrCallback.cycle_mult == 1):\n",
    "            self.active = False\n",
    "            \n",
    "    def update_average_model(self):\n",
    "        # update running average of parameters\n",
    "        print(\"model is {} epochs old\".format(self.swa_n))\n",
    "        for model_param, swa_param in zip(self.model.get_weights(), self.swa_model):\n",
    "            swa_param *= self.swa_n\n",
    "            swa_param += model_param\n",
    "            swa_param /= (self.swa_n + 1)\n",
    "        \n",
    "        if self.swa_n > self.swaRenewal and self.first_completed:\n",
    "            print(\"new model is {} epochs old\".format(self.n_since_renewal))\n",
    "            for model_param, swa_param in zip(self.model.get_weights(), self.swa_model_new):\n",
    "                swa_param *= self.n_since_renewal\n",
    "                swa_param += model_param\n",
    "                swa_param /= (self.n_since_renewal + 1)\n",
    "            \n",
    "    def compareAverages(self):\n",
    "        if isinstance(self.losses['swa'], type(None)):\n",
    "            self.test_model.set_weights(self.swa_model)\n",
    "            if self.weighted:\n",
    "                self.losses['swa'] = self.test_model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], sample_weight=self.testBatch['weights'], verbose=0)\n",
    "            else:\n",
    "                self.losses['swa'] = self.test_model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], verbose=0)\n",
    "        \n",
    "        self.test_model.set_weights(self.swa_model_new)\n",
    "        if self.weighted:\n",
    "            new_loss = self.test_model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], sample_weight=self.testBatch['weights'], verbose=0)\n",
    "        else:\n",
    "            new_loss = self.test_model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], verbose=0)\n",
    "        \n",
    "        print(\"Checking renewal swa model, current model: {}, new model: {}\".format(self.losses['swa'], new_loss))\n",
    "        if new_loss < self.losses['swa']:\n",
    "            print(\"New model better, replacing\\n____________________\\n\\n\")\n",
    "            self.losses['swa'] = new_loss\n",
    "            if sgdReplacement:\n",
    "                self.model.set_weights(self.swa_model)\n",
    "                self.n_since_renewal = 0\n",
    "            else:\n",
    "                self.n_since_renewal = 1\n",
    "            self.swa_model[:] = self.swa_model_new\n",
    "            self.swa_model_new = self.model.get_weights()\n",
    "            self.swa_n = self.n_since_renewal\n",
    "            self.cylcle_since_replacement = 1\n",
    "\n",
    "        else:\n",
    "            print(\"Current model better, renewing\\n____________________\\n\\n\")\n",
    "            self.swa_model_new = self.model.get_weights()\n",
    "            self.n_since_renewal = 1\n",
    "            self.test_model.set_weights(self.swa_model)\n",
    "            self.cylcle_since_replacement += 1\n",
    "                \n",
    "    \n",
    "    def get_losses(self):\n",
    "        if isinstance(self.losses['swa'], type(None)):\n",
    "            self.test_model.set_weights(self.swa_model)\n",
    "            if self.weighted:\n",
    "                self.losses['swa'] = self.test_model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], sample_weight=self.testBatch['weights'], verbose=0)\n",
    "            else:\n",
    "                self.losses['swa'] = self.test_model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], verbose=0)\n",
    "        \n",
    "        if isinstance(self.losses['base'], type(None)):\n",
    "            if self.weighted:\n",
    "                self.losses['base'] = self.model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], sample_weight=self.testBatch['weights'], verbose=0)\n",
    "            else:\n",
    "                self.losses['base'] = self.model.evaluate(self.testBatch['inputs'], self.testBatch['targets'], verbose=0)\n",
    "        \n",
    "        return self.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results, histories = _batchTrainClassifier(trainData, nSplits, getModel, modelParams, trainParams, swaStart=1,\n",
    "                                          patience=50, swaRenewal=5, trainOnWeights=True,\n",
    "                                          maxEpochs=maxEpochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_weights/resultsFile.pkl', 'r') as fin:   \n",
    "    results = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble, weights = assembleEnsemble(results, ensembleSize, ensembleMode, compileArgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = False, reflect = True, augRotMult=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in xrange(10):\n",
    "    tmpPred = []\n",
    "    for aug in range(valData.augMult):\n",
    "        batch = valData.getTestBatch(i, aug)['inputs']\n",
    "        tmpPred.append(ensemblePredict(batch, ensemble, weights, n=1))\n",
    "    pred.append(np.array(tmpPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tPred = np.concatenate(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(getFeature('targets', valData.source), columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in xrange(tPred.shape[0]):\n",
    "    df['pred_'+ str(p)] = tPred[p,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'pred_mean'] = np.mean(df[[x for x in df.columns if 'pred' in x]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rot 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RotRef 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RotRef 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RotRef 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RotRef 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amsScanQuick(inData, wFactor=250000./50000.):\n",
    "    s = np.sum(inData.loc[inData['gen_target'] == 1, 'gen_weight'])\n",
    "    b = np.sum(inData.loc[inData['gen_target'] == 0, 'gen_weight'])\n",
    "    tIIs = inData['pred_class'].argsort()\n",
    "    amss = np.empty([len(tIIs)])\n",
    "    \n",
    "    amsMax = 0\n",
    "    threshold = 0.0\n",
    "\n",
    "    for tI in range(len(tIIs)):\n",
    "        # don't forget to renormalize the weights to the same sum \n",
    "        # as in the complete training set\n",
    "        amss[tI] = AMS(max(0,s * wFactor),max(0,b * wFactor))\n",
    "        if amss[tI] > amsMax:\n",
    "            amsMax = amss[tI]\n",
    "            threshold = inData['pred_class'].values[tIIs[tI]]\n",
    "            #print tI,threshold\n",
    "        if inData.loc[:, 'gen_target'].values[tIIs[tI]]:\n",
    "            s -= inData.loc[:, 'gen_weight'].values[tIIs[tI]]\n",
    "        else:\n",
    "            b -= inData.loc[:, 'gen_weight'].values[tIIs[tI]]\n",
    "    print amsMax, threshold\n",
    "    return amsMax, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = BatchYielder(h5py.File(dirLoc + 'val.hdf5', \"r+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = False, reflect = True, augRotMult=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = False, augRotMult=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = False, augRotMult=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = False, augRotMult=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = False, augRotMult=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = False, augRotMult=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = False, augRotMult=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, \n",
    "                     RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'testing.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=8),\n",
    "                     ensembleSize=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTest(0.9632657, 'Day_10_basic_rotref8_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c higgs-boson -f ../Data/Day_10_basic_rotref8_5_test.csv -m\"Day_10 basic rotref8 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 8 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut = amsScanQuick(convertToDF(valData.source))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFrame = pandas.DataFrame()\n",
    "trainFrame['gen_target'] = getFeature('targets', trainData.source)\n",
    "trainFrame['gen_weight'] = getFeature('weights', trainData.source)\n",
    "valFrame = convertToDF(valData.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigFactor = (len(trainFrame.loc[trainFrame.gen_target == 1, 'gen_weight'])+len(valFrame.loc[valFrame.gen_target == 1, 'gen_weight']))/len(valFrame.loc[valFrame.gen_target == 1, 'gen_weight'])\n",
    "bkgFactor = (len(trainFrame.loc[trainFrame.gen_target == 0, 'gen_weight'])+len(valFrame.loc[valFrame.gen_target == 0, 'gen_weight']))/len(valFrame.loc[valFrame.gen_target == 0, 'gen_weight'])\n",
    "print sigFactor, bkgFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amsScanQuick(inData, sigFactor=250000./50000., bkgFactor=250000./50000.):\n",
    "    s = np.sum(inData.loc[inData['gen_target'] == 1, 'gen_weight'])\n",
    "    b = np.sum(inData.loc[inData['gen_target'] == 0, 'gen_weight'])\n",
    "    tIIs = inData['pred_class'].argsort()\n",
    "    amss = np.empty([len(tIIs)])\n",
    "    \n",
    "    amsMax = 0\n",
    "    threshold = 0.0\n",
    "\n",
    "    for tI in range(len(tIIs)):\n",
    "        # don't forget to renormalize the weights to the same sum \n",
    "        # as in the complete training set\n",
    "        amss[tI] = AMS(max(0,s * sigFactor),max(0,b * bkgFactor))\n",
    "        if amss[tI] > amsMax:\n",
    "            amsMax = amss[tI]\n",
    "            threshold = inData['pred_class'].values[tIIs[tI]]\n",
    "            #print tI,threshold\n",
    "        if inData.loc[:, 'gen_target'].values[tIIs[tI]]:\n",
    "            s -= inData.loc[:, 'gen_weight'].values[tIIs[tI]]\n",
    "        else:\n",
    "            b -= inData.loc[:, 'gen_weight'].values[tIIs[tI]]\n",
    "    print amsMax, threshold\n",
    "    return amsMax, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsScanQuick(valFrame, sigFactor, bkgFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amsScan(inData, scale=False):\n",
    "    best = [0,-1]\n",
    "    ams = []\n",
    "    for index, row in inData.iterrows():\n",
    "        s = wFactor*np.sum(inData.loc[(inData['pred_class'] >= row['pred_class']) & (inData['gen_target'] == 1), 'gen_weight'])\n",
    "        b = wFactor*np.sum(inData.loc[(inData['pred_class'] >= row['pred_class']) & (inData['gen_target'] == 0), 'gen_weight'])\n",
    "        ams.append(AMS(s, b))\n",
    "        if ams[-1] > best[1]:\n",
    "            best = [row['pred_class'], ams[-1]]\n",
    "    print best\n",
    "    return ams, best\n",
    "\n",
    "def foldAMSScan(inData, N=10):\n",
    "    kf = StratifiedKFold(n_splits=N, shuffle=True)\n",
    "    folds = kf.split(inData, inData['gen_target'])\n",
    "    bests = []\n",
    "    for i, (train, test) in enumerate(folds):\n",
    "        bests.append(amsScan(inData.iloc[test], (np.sum(inData[(inData['gen_target'] == 1)]['gen_weight']), np.sum(inData[(inData['gen_target'] == 0)]['gen_weight'])))[1])\n",
    "        print \"Fold {}, best AMS {} at cut of {}. Total weights Signal:Bkg. {}:{}\".format(i, bests[-1][1], bests[-1][0],\n",
    "                                                                                          np.sum(inData.iloc[test][inData.gen_target == 1]['gen_weight']),\n",
    "                                                                                          np.sum(inData.iloc[test][inData.gen_target == 0]['gen_weight']))\n",
    "    print \"Mean cut\", np.average([x[0] for x in bests], weights=[1/x[1] for x in bests]), \"mean AMS\", np.average([x[1] for x in bests], weights=[1/x[1] for x in bests])\n",
    "    return bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests = foldAMSScan(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.average([x[0] for x in bests])\n",
    "print np.average([x[0] for x in bests], weights=[1/x[1] for x in bests])\n",
    "print np.average([x[0] for x in bests], weights=[x[1] for x in bests])\n",
    "print np.average([x[0] for x in bests], weights=[1.7448610687361392-x[1] for x in bests])\n",
    "print np.average([x[0] for x in bests], weights=[1/np.abs(1.7448610687361392-x[1]) for x in bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, \n",
    "                     RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'testing.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=8),\n",
    "                     ensembleSize=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTest(0.9557010754710975, 'Day_10_M_rotref8_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c higgs-boson -f ../Data/Day_10_M_rotref8_10_test.csv -m\"Day_10 minus rotref8 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on validation data Rot-Ref 16 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, valData, ensembleSize=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Testing ROC AUC: unweighted {}, weighted {}'.format(roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source)),\n",
    "                                                           roc_auc_score(getFeature('targets', valData.source), getFeature('pred', valData.source), sample_weight=getFeature('weights', valData.source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsScanQuick(convertToDF(valData.source), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests = foldAMSScan(convertToDF(valData.source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Mean', np.average([x[0] for x in bests])\n",
    "print 'Inverse-AMS-weighted mean', np.average([x[0] for x in bests], weights=[1/x[1] for x in bests])\n",
    "print 'AMS-weighted mean', np.average([x[0] for x in bests], weights=[x[1] for x in bests])\n",
    "print 'AMS-Difference-weighted mean', np.average([x[0] for x in bests], weights=[1.7472080023156094-x[1] for x in bests])\n",
    "print 'Inverse AMS-Difference-weighted mean', np.average([x[0] for x in bests], weights=[1/np.abs(1.7472080023156094-x[1]) for x in bests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchEnsemblePredict(ensemble, weights, \n",
    "                     RotationReflectionBatch(classTrainFeatures, h5py.File(dirLoc + 'testing.hdf5', \"r+\"), inputPipe=inputPipe,\n",
    "                                  rotate = True, reflect = True, augRotMult=16),\n",
    "                     ensembleSize=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTest(0.95, 'Day_10_95_rotref16_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c higgs-boson -f ../Data/Day_10_95_rotref16_10_test.csv -m\"Day_10 95 rotref16 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
