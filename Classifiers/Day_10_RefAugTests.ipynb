{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 10\n",
    "batch size 256 lr 1e-3, normed weighted, non-rotated, cartesian,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/giles/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import sys\n",
    "import os\n",
    "os.environ['MKL_THREADING_LAYER']='GNU'\n",
    "sys.path.append('../')\n",
    "from Modules.Basics import *\n",
    "from Modules.Class_Basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on 31 features: ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_met_pt', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_all_pt', 'PRI_tau_px', 'PRI_tau_py', 'PRI_tau_pz', 'PRI_lep_px', 'PRI_lep_py', 'PRI_lep_pz', 'PRI_jet_leading_px', 'PRI_jet_leading_py', 'PRI_jet_leading_pz', 'PRI_jet_subleading_px', 'PRI_jet_subleading_py', 'PRI_jet_subleading_pz', 'PRI_met_px', 'PRI_met_py']\n"
     ]
    }
   ],
   "source": [
    "classTrainFeatures = ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_met_pt', 'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_all_pt', 'PRI_tau_px', 'PRI_tau_py', 'PRI_tau_pz', 'PRI_lep_px', 'PRI_lep_py', 'PRI_lep_pz', 'PRI_jet_leading_px', 'PRI_jet_leading_py', 'PRI_jet_leading_pz', 'PRI_jet_subleading_px', 'PRI_jet_subleading_py', 'PRI_jet_subleading_pz', 'PRI_met_px', 'PRI_met_py']\n",
    "classModel = 'modelSwish'\n",
    "varSet = \"basic_features\"\n",
    "\n",
    "nSplits = 10\n",
    "ensembleSize = 1\n",
    "ensembleMode = 'loss'\n",
    "\n",
    "maxEpochs = 200\n",
    "compileArgs = {'loss':'binary_crossentropy', 'optimizer':'adam'}\n",
    "trainParams = {'epochs' : 1, 'batch_size' : 256, 'verbose' : 0}\n",
    "modelParams = {'version':classModel, 'nIn':len(classTrainFeatures), 'compileArgs':compileArgs, 'mode':'classifier'}\n",
    "\n",
    "print \"\\nTraining on\", len(classTrainFeatures), \"features:\", [var for var in classTrainFeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = BatchYielder(h5py.File(dirLoc + 'train.hdf5', \"r+\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lrFinder = batchLRFind(trainData, getModel, modelParams, trainParams,\n",
    "                       lrBounds=[1e-5,1e-1], trainOnWeights=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compileArgs['lr'] = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results, histories = batchTrainClassifier(trainData, nSplits, getModel, modelParams, trainParams,\n",
    "                                          patience=2, cosAnnealMult=2, reduxDecay=True, trainOnWeights=True,\n",
    "                                          maxEpochs=maxEpochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_weights/resultsFile.pkl', 'r') as fin:   \n",
    "    results = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing ensemble by loss\n",
      "Model 0 is 0 with loss = 3.1850099291083325e-05\n"
     ]
    }
   ],
   "source": [
    "ensemble, weights = assembleEnsemble(results, ensembleSize, ensembleMode, compileArgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response on val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectBatch(BatchYielder):\n",
    "    def __init__(self, header, datafile=None, inputPipe=None, trainTimeAug=True, testTimeAug=True):\n",
    "        self.header = header\n",
    "        self.augmented = True\n",
    "        self.augMult = 8\n",
    "        self.trainTimeAug = trainTimeAug\n",
    "        self.testTimeAug = testTimeAug\n",
    "        self.inputPipe = inputPipe\n",
    "        if not isinstance(datafile, types.NoneType):\n",
    "            self.addSource(datafile)\n",
    "        \n",
    "    def getBatch(self, index, datafile=None):\n",
    "        if isinstance(datafile, types.NoneType):\n",
    "            datafile = self.source\n",
    "            \n",
    "        index = str(index)\n",
    "        weights = None\n",
    "        targets = None\n",
    "        if 'fold_' + index + '/weights' in datafile:\n",
    "            weights = np.array(datafile['fold_' + index + '/weights'])\n",
    "        if 'fold_' + index + '/targets' in datafile:\n",
    "            targets = np.array(datafile['fold_' + index + '/targets'])\n",
    "\n",
    "        if isinstance(self.inputPipe, types.NoneType):\n",
    "            inputs = pandas.DataFrame(np.array(datafile['fold_' + index + '/inputs']), columns=self.header)\n",
    "        else:\n",
    "            inputs = pandas.DataFrame(self.inputPipe.inverse_transform(np.array(datafile['fold_' + index + '/inputs'])), columns=self.header)            \n",
    "        for coord in ['_px','_py','_pz']:\n",
    "            inputs['aug' + coord] = np.random.randint(0, 2, size=len(inputs))\n",
    "            for feat in [x for x in inputs.columns if coord in x and x != 'aug' + coord]:\n",
    "                cut = (inputs['aug' + coord] == 1)\n",
    "                if 'jet_leading' in feat:\n",
    "                    cut = cut & (inputs.PRI_jet_num >= 0.9)\n",
    "                elif 'jet_subleading' in feat:\n",
    "                    cut = cut & (inputs.PRI_jet_num >= 1.9)\n",
    "                inputs.loc[cut, feat] = -inputs.loc[cut, feat]\n",
    "        if isinstance(self.inputPipe, types.NoneType):\n",
    "            inputs = inputs[self.header].values\n",
    "        else:\n",
    "            inputs = inputPipe.transform(inputs[self.header].values)\n",
    "\n",
    "        return {'inputs':inputs,\n",
    "                'targets':targets,\n",
    "                'weights':weights}\n",
    "    \n",
    "    def getTestBatch(self, index, augIndex, datafile=None):\n",
    "        if augIndex >= self.augMult:\n",
    "            print \"Invalid augmentation index passed\", augIndex\n",
    "            return -1\n",
    "        \n",
    "        if isinstance(datafile, types.NoneType):\n",
    "            datafile = self.source\n",
    "            \n",
    "        index = str(index)\n",
    "        weights = None\n",
    "        targets = None\n",
    "        if 'fold_' + index + '/weights' in datafile:\n",
    "            weights = np.array(datafile['fold_' + index + '/weights'])\n",
    "        if 'fold_' + index + '/targets' in datafile:\n",
    "            targets = np.array(datafile['fold_' + index + '/targets'])\n",
    "\n",
    "        augMode = '{0:03b}'.format(augIndex) #Get binary rep\n",
    "        if isinstance(self.inputPipe, types.NoneType):\n",
    "            inputs = pandas.DataFrame(np.array(datafile['fold_' + index + '/inputs']), columns=self.header)\n",
    "        else:\n",
    "            inputs = pandas.DataFrame(self.inputPipe.inverse_transform(np.array(datafile['fold_' + index + '/inputs'])), columns=self.header)            \n",
    "        coords = ['_px','_py','_pz']\n",
    "        for coordIndex, active in enumerate(augMode):\n",
    "            if active == '1':\n",
    "                for feat in [x for x in inputs.columns if coords[coordIndex] in x]:\n",
    "                    if 'jet_leading' in feat:\n",
    "                        inputs.loc[inputs.PRI_jet_num >= 0.9, feat] = -inputs.loc[inputs.PRI_jet_num >= 0.9, feat]\n",
    "                    elif 'jet_subleading' in feat:\n",
    "                        inputs.loc[inputs.PRI_jet_num >= 1.9, feat] = -inputs.loc[inputs.PRI_jet_num >= 1.9, feat]\n",
    "                    else:\n",
    "                        inputs.loc[:, feat] = -inputs.loc[:, feat]\n",
    "        if isinstance(self.inputPipe, types.NoneType):\n",
    "            inputs = inputs[self.header].values\n",
    "        else:\n",
    "            inputs = inputPipe.transform(inputs[self.header].values)\n",
    "\n",
    "        return {'inputs':inputs,\n",
    "                'targets':targets,\n",
    "                'weights':weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dirLoc + 'inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = ReflectBatch(classTrainFeatures, h5py.File(dirLoc + 'val.hdf5', \"r+\"), inputPipe=inputPipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in xrange(10):\n",
    "    tmpPred = []\n",
    "    for aug in range(valData.augMult):\n",
    "        batch = valData.getTestBatch(i, aug)['inputs']\n",
    "        tmpPred.append(ensemblePredict(batch, ensemble, weights, n=1))\n",
    "    pred.append(np.array(tmpPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tPred = np.concatenate(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(getFeature('targets', valData.source), columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in xrange(tPred.shape[0]):\n",
    "    df['pred_'+ str(p)] = tPred[p,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'pred_mean'] = np.mean(df[[x for x in df.columns if 'pred' in x]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5310504933255948"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204760451632591"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52412"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref veto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5310504933255948"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)])/len(df[(df.target == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204760451632591"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])/len(df[(df.target == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52412"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df[(df.target == 0) & (df.pred_0 < df.pred_mean)])+len(df[(df.target == 1) & (df.pred_0 > df.pred_mean)]))/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
